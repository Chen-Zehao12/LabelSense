{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '50%*1'\n",
    "\n",
    "train, test = [], []\n",
    "\n",
    "with open('origin/text_train') as f:\n",
    "    text_train = f.readlines()\n",
    "with open('origin/label_train') as f:\n",
    "    label_train = f.readlines()\n",
    "\n",
    "for text, labels in zip(text_train, label_train):\n",
    "    train.append({\n",
    "        'text': text.strip(),\n",
    "        'labels': labels.strip().split()\n",
    "    })\n",
    "\n",
    "with open('origin/text_test') as f:\n",
    "    text_test = f.readlines()\n",
    "with open('origin/label_test') as f:\n",
    "    label_test = f.readlines()\n",
    "\n",
    "for text, labels in zip(text_test, label_test):\n",
    "    test.append({\n",
    "        'text': text.strip(),\n",
    "        'labels': labels.strip().split()\n",
    "    })\n",
    "\n",
    "with open('origin/text_val') as f:\n",
    "    text_val = f.readlines()\n",
    "with open('origin/label_val') as f:\n",
    "    label_val = f.readlines()\n",
    "\n",
    "for text, labels in zip(text_val, label_val):\n",
    "    test.append({\n",
    "        'text': text.strip(),\n",
    "        'labels': labels.strip().split()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete \\n and \\\n",
    "for line in train:\n",
    "    line['text'] = line['text'].replace('\\n', ' ')\n",
    "    line['text'] = line['text'].replace('\\\\', '')\n",
    "\n",
    "for line in test:\n",
    "    line['text'] = line['text'].replace('\\n', ' ')\n",
    "    line['text'] = line['text'].replace('\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count classes\n",
    "train_class_count = defaultdict(int)\n",
    "test_class_count = defaultdict(int)\n",
    "\n",
    "for line in train:\n",
    "    for label in line['labels']:\n",
    "        train_class_count[label] += 1\n",
    "\n",
    "for line in test:\n",
    "    for label in line['labels']:\n",
    "        test_class_count[label] += 1\n",
    "\n",
    "unseen_class_count = train_class_count.keys() - test_class_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 53840\n",
      "Number of test data: 2000\n",
      "Number of classes in train data: 54\n",
      "Number of classes in test data: 54\n",
      "Number of unseen classes: 0\n",
      "Count of train label:\n",
      " [('cs.IT', 17152), ('math.IT', 17152), ('cs.LG', 8007), ('cs.AI', 4991), ('stat.ML', 4939), ('cs.DS', 4673), ('cs.DM', 4074), ('cs.SI', 4003), ('cs.LO', 3517), ('math.CO', 3355), ('physics.soc-ph', 3329), ('cs.NI', 3081), ('cs.CC', 3079), ('math.OC', 3043), ('cs.CL', 2831), ('cs.CV', 2774), ('cs.CR', 2723), ('cs.DC', 2259), ('cs.SY', 2242), ('cs.NE', 2024), ('cs.IR', 2018), ('cs.GT', 1720), ('quant-ph', 1581), ('cs.CY', 1572), ('cs.PL', 1382), ('cs.DB', 1267), ('cs.SE', 1261), ('math.PR', 1194), ('cs.CG', 1080), ('cs.NA', 1052), ('cs.HC', 1005), ('cs.MA', 956), ('math.NA', 945), ('cs.CE', 923), ('cs.RO', 921), ('cs.FL', 915), ('math.ST', 875), ('stat.TH', 875), ('cs.DL', 867), ('cmp-lg', 856), ('cs.MM', 711), ('cs.PF', 687), ('math.LO', 667), ('cond-mat.stat-mech', 664), ('stat.AP', 628), ('stat.ME', 503), ('cs.MS', 484), ('cond-mat.dis-nn', 440), ('q-bio.NC', 408), ('cs.SC', 391), ('math.NT', 386), ('physics.data-an', 385), ('q-bio.QM', 376), ('nlin.AO', 350)]\n",
      "Count of test label:\n",
      " [('cs.IT', 683), ('math.IT', 683), ('cs.LG', 294), ('cs.AI', 211), ('stat.ML', 185), ('cs.DS', 161), ('cs.DM', 137), ('cs.SI', 134), ('cs.LO', 132), ('math.CO', 119), ('physics.soc-ph', 113), ('cs.NI', 106), ('cs.CC', 102), ('math.OC', 102), ('cs.CL', 99), ('cs.CR', 98), ('cs.CV', 95), ('cs.NE', 80), ('cs.IR', 77), ('cs.DC', 74), ('cs.SY', 72), ('cs.GT', 64), ('cs.CY', 61), ('quant-ph', 61), ('cs.PL', 59), ('cs.DB', 49), ('cs.SE', 48), ('cs.MA', 39), ('cs.NA', 39), ('cs.CG', 38), ('cs.FL', 37), ('math.NA', 37), ('cs.CE', 36), ('math.ST', 36), ('stat.TH', 36), ('math.PR', 35), ('cs.RO', 34), ('cmp-lg', 33), ('cond-mat.stat-mech', 33), ('cs.DL', 31), ('cs.PF', 29), ('cs.HC', 28), ('cs.MM', 28), ('math.LO', 26), ('stat.AP', 21), ('cond-mat.dis-nn', 19), ('cs.SC', 19), ('physics.data-an', 16), ('nlin.AO', 14), ('q-bio.NC', 13), ('stat.ME', 13), ('cs.MS', 12), ('q-bio.QM', 11), ('math.NT', 9)]\n"
     ]
    }
   ],
   "source": [
    "print('Number of train data:', len(train))\n",
    "print('Number of test data:', len(test))\n",
    "\n",
    "print('Number of classes in train data:', len(train_class_count))\n",
    "print('Number of classes in test data:', len(test_class_count))\n",
    "print('Number of unseen classes:', len(unseen_class_count))\n",
    "\n",
    "print('Count of train label:\\n', sorted(train_class_count.items(), key=lambda x: -x[1]))\n",
    "print('Count of test label:\\n', sorted(test_class_count.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length of train text: 984.6816121842496\n",
      "Avg length of test text: 981.3435\n"
     ]
    }
   ],
   "source": [
    "train_text_length, test_text_length = 0, 0\n",
    "for line in train:\n",
    "    train_text_length += len(line['text'])\n",
    "for line in test:\n",
    "    test_text_length += len(line['text'])\n",
    "\n",
    "print('Avg length of train text:', train_text_length / len(train))\n",
    "print('Avg length of test text:', test_text_length / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label2id\n",
    "label2id = dict()\n",
    "cnt = 0\n",
    "\n",
    "for line in train:\n",
    "    for label in line['labels']:\n",
    "        if label not in label2id:\n",
    "            label2id[label] = cnt\n",
    "            cnt += 1\n",
    "\n",
    "for line in test:\n",
    "    for label in line['labels']:\n",
    "        if label not in label2id:\n",
    "            label2id[label] = cnt\n",
    "            cnt += 1\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to one label, labels[0] is the rarest one\n",
    "for line in train:\n",
    "    minn, minn_label = 20000, ''\n",
    "    for label in line['labels']:\n",
    "        if train_class_count[label] < minn:\n",
    "            minn = train_class_count[label]\n",
    "            minn_label = label\n",
    "    if line['labels'][0] != minn_label:\n",
    "        line['labels'].remove(minn_label)\n",
    "        line['labels'].insert(0, minn_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete long tail data\n",
    "label_collection = [[] for _ in range(len(train_class_count))]\n",
    "for line in train:\n",
    "    idx = label2id[line['labels'][0]]\n",
    "    label_collection[idx].append(line)\n",
    "\n",
    "if state == '50%*1':\n",
    "    threshold = int(np.percentile([len(t) for t in label_collection], 50))\n",
    "    label_collection = [t[:threshold * 1] for t in label_collection if len(t) >= threshold]\n",
    "elif state == '25%*3':\n",
    "    threshold = int(np.percentile([len(t) for t in label_collection], 25))\n",
    "    label_collection = [t[:threshold * 3] for t in label_collection if len(t) >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh label2id\n",
    "label2id = dict()\n",
    "for idx, piece in enumerate(label_collection):\n",
    "    label2id[piece[0]['labels'][0]] = idx\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unseen test\n",
    "idx = 0\n",
    "while idx < len(test):\n",
    "    for label in test[idx]['labels']:\n",
    "        if label not in label2id:\n",
    "            test.pop(idx)\n",
    "            break\n",
    "    else:\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{state}/id2label.json', 'w') as f:\n",
    "    json.dump(id2label, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(f'{state}/label2id.json', 'w') as f:\n",
    "    json.dump(label2id, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle train dataset\n",
    "collection_pointer = [0] * len(label_collection)\n",
    "\n",
    "shuffle_train = []\n",
    "global_idx, idx = 0, 0\n",
    "while global_idx < sum(len(t) for t in label_collection):\n",
    "    if collection_pointer[idx] < len(label_collection[idx]):\n",
    "        shuffle_train.append(label_collection[idx][collection_pointer[idx]])\n",
    "        collection_pointer[idx] += 1\n",
    "        idx = (idx + 1) % len(label_collection)\n",
    "        global_idx += 1\n",
    "    else:\n",
    "        idx = (idx + 1) % len(label_collection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of test\n",
    "test = test[:len(shuffle_train) * 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 20385\n",
      "Number of test data: 312\n"
     ]
    }
   ],
   "source": [
    "print('Number of train data:', len(shuffle_train))\n",
    "print('Number of test data:', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unseen train labels\n",
    "for line in shuffle_train:\n",
    "    idx = 0\n",
    "    while idx < len(line['labels']):\n",
    "        if line['labels'][idx] not in label2id:\n",
    "            line['labels'].pop(idx)\n",
    "        else:\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 20385\n",
      "Number of test data: 312\n",
      "Number of classes in train data: 27\n",
      "Number of classes in test data: 26\n",
      "Number of unseen classes: 1\n",
      "Count of train label:\n",
      " [('cs.IT', 3110), ('cs.CL', 2190), ('math.OC', 1793), ('stat.ML', 1768), ('cs.NI', 1704), ('cs.CC', 1564), ('math.CO', 1542), ('cs.CR', 1520), ('cs.CV', 1388), ('cs.DC', 1315), ('physics.soc-ph', 1259), ('cs.SY', 1252), ('cs.CY', 1153), ('cs.GT', 1087), ('cs.PL', 1084), ('cs.IR', 1051), ('cs.SE', 918), ('cs.NE', 907), ('cs.DB', 845), ('quant-ph', 832), ('cs.MA', 825), ('cs.HC', 819), ('cs.CG', 796), ('math.PR', 785), ('cs.RO', 759), ('cs.FL', 755), ('cmp-lg', 755)]\n",
      "Count of test label:\n",
      " [('cs.CL', 53), ('cs.CR', 50), ('cs.SY', 45), ('math.OC', 42), ('cs.NI', 35), ('cs.CC', 34), ('cmp-lg', 33), ('cs.CY', 33), ('cs.CV', 31), ('cs.IR', 28), ('cs.DC', 25), ('quant-ph', 25), ('cs.PL', 25), ('cs.NE', 25), ('cs.SE', 24), ('cs.GT', 21), ('cs.DB', 21), ('cs.FL', 20), ('cs.HC', 20), ('cs.MA', 17), ('cs.RO', 17), ('math.CO', 14), ('stat.ML', 8), ('cs.CG', 5), ('physics.soc-ph', 4), ('math.PR', 4)]\n",
      "Avg length of train text: 976.3287711552612\n",
      "Avg length of test text: 939.5929487179487\n"
     ]
    }
   ],
   "source": [
    "# count classes\n",
    "train_class_count = defaultdict(int)\n",
    "test_class_count = defaultdict(int)\n",
    "\n",
    "for line in shuffle_train:\n",
    "    for label in line['labels']:\n",
    "        train_class_count[label] += 1\n",
    "\n",
    "for line in test:\n",
    "    for label in line['labels']:\n",
    "        test_class_count[label] += 1\n",
    "\n",
    "unseen_class_count = train_class_count.keys() - test_class_count.keys()\n",
    "print('Number of train data:', len(shuffle_train))\n",
    "print('Number of test data:', len(test))\n",
    "\n",
    "print('Number of classes in train data:', len(train_class_count))\n",
    "print('Number of classes in test data:', len(test_class_count))\n",
    "print('Number of unseen classes:', len(unseen_class_count))\n",
    "\n",
    "print('Count of train label:\\n', sorted(train_class_count.items(), key=lambda x: -x[1]))\n",
    "print('Count of test label:\\n', sorted(test_class_count.items(), key=lambda x: -x[1]))\n",
    "\n",
    "train_text_length, test_text_length = 0, 0\n",
    "for line in shuffle_train:\n",
    "    train_text_length += len(line['text'])\n",
    "for line in test:\n",
    "    test_text_length += len(line['text'])\n",
    "\n",
    "print('Avg length of train text:', train_text_length / len(shuffle_train))\n",
    "print('Avg length of test text:', test_text_length / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label description\n",
    "with open('label-description.jsonl') as f:\n",
    "    label_desc = f.readlines()\n",
    "    label_desc = list(map(json.loads, label_desc))\n",
    "    label_desc = {line['label']: line['description'] for line in label_desc}\n",
    "\n",
    "for line in shuffle_train:\n",
    "    label_text = line['labels'][0]\n",
    "    for i, label in enumerate(line['labels']):\n",
    "        line['labels'][i] = label2id[label]\n",
    "    line['label_description'] = label_desc[label_text]\n",
    "\n",
    "for line in test:\n",
    "    label_text = line['labels'][0]\n",
    "    for i, label in enumerate(line['labels']):\n",
    "        line['labels'][i] = label2id[label]\n",
    "    line['label_description'] = label_desc[label_text]\n",
    "\n",
    "with open(f'{state}/train.json', 'w') as f:\n",
    "    json.dump(shuffle_train, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(f'{state}/test.json', 'w') as f:\n",
    "    json.dump(test, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label description\n",
    "with open('label-description-with-example.jsonl') as f:\n",
    "    label_desc = f.readlines()\n",
    "    label_desc = list(map(json.loads, label_desc))\n",
    "    label_desc = {line['label']: line['description'] for line in label_desc}\n",
    "\n",
    "for line in shuffle_train:\n",
    "    label_text = id2label[line['labels'][0]]\n",
    "    line['label_description'] = label_desc[label_text]\n",
    "\n",
    "for line in test:\n",
    "    label_text = id2label[line['labels'][0]]\n",
    "    line['label_description'] = label_desc[label_text]\n",
    "\n",
    "with open(f'{state}/train-with-example.json', 'w') as f:\n",
    "    json.dump(shuffle_train, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(f'{state}/test-with-example.json', 'w') as f:\n",
    "    json.dump(test, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
